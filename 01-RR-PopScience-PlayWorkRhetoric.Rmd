---
title: "01-RR-PopScience-PlayWorkRhetoric"
author: "Anoff Nicholas Cobblah"
date: "July 31, 2018"
output: html_document
  html_document:
    number_sections: yes
    toc: true
    toc_depth: 6
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### December 2017: "play", "player", "recreation", "work", "worker", and "labor" in Victorian Popular Science

This script combines my Word Flagging and KWIC (tokenizer script) methods in order to create an interactive illustration of the frequency with which the terms "play", "player", "recreation", "work", "worker", and "labor" were referenced in Victorian Popular Science. The goal is to determine whether references to work and play make up a larger proportion of the corpus at the end of the century than at the beginning, and to visualize this in such a way that scrolling over a point automatically produces a key words in context (randomly).

First we set the parameters.

**IMPORTANT NOTE: Since creating a Word Flag matrix can take a nontrivial amount of time for larger corpuses, this script is designed only to run the program to create a new PopSciWordFlagdf if there is a change to the dataset in folder "Documents" or if the previous PopSciWordFlagdf has been deleted.**

```{r,  eval=FALSE}
    PopScilocation <- paste0(getwd(),"/Applications/Victorian-Popular-Science")
    PopScidoclocation <- paste0(PopScilocation,"/Documents")
    PopScilongconlength <- 250
    PopScishortconlength <- 3
    PopSciPOSconlength <- 10
    PopSciplaysearchedtermlist <- c("play", "player", "recreation")
    PopSciworksearchedtermlist <- c("work", "worker","labor")
    PopScisearchedtermlist <- c(PopSciplaysearchedtermlist,PopSciworksearchedtermlist)
    PopScioutputlocation <- PopScilocation
    PopSciWordFlagdfPath <- paste0(PopScioutputlocation,"/","PopSciWordFlagdf.txt")
    PopSciDocumentSize <- 152896399
```

To create the data frame compiling every reference to a term, or load in the previous data frame if nothing has changed, we run the following script.

```{r DecPopSciApp Word Flag,  eval=FALSE}
      if(sum(file.info(list.files(PopScidoclocation, all.files = TRUE, recursive = TRUE, full.names=TRUE))$size) == PopSciDocumentSize) {
        PopSciDataChange1 <- FALSE
        print("The data in the 'Documents' folder appears not to have changed.")
      }else{
        PopSciDataChange1 <- TRUE
        print("The data in the 'Documents' folder appears to have been changed. A new PopSciWordFlagdf will therefore be created. TO UPDATE THIS SCRIPT, PLEASE CHANGE THE PopSciDocumentSize TO REFLECT THE NEW SIZE OF THE DOCUMENTS.")
        }
      
      if(file.exists(PopSciWordFlagdfPath) == TRUE) {
        PopSciDataChange2 <- FALSE
        print("The previous PopSciWordFlagdf still exists.")
      }else{
        PopSciDataChange2 <- TRUE
        print("The previous PopSciwordFlagdf seems to have been moved or deleted.  A new PopSciWordFlag will therefore be created.")
        }

  if(PopSciDataChange1|PopSciDataChange2 == TRUE) {
  
      files <- list.files(path = PopScidoclocation, pattern = "txt", full.names = TRUE) #creates vector of txt file names.
      if(file.exists(PopScioutputlocation) == FALSE){dir.create(PopScioutputlocation)}
      PopScistemsearchedtermlist <- unique(wordStem(PopScisearchedtermlist)) #lemmatizes the list of terms you want to search for.
      PopSciWordFlagmat <- matrix(,ncol=12,nrow=1)
      for (i in 1:length(files)) {
        fileName <- read_file(files[i])
        Encoding(fileName) <- "UTF-8"  #since tokenize_sentences function requires things to be encoded in UTF-8, need to remove some data.
        fileName <- iconv(fileName, "UTF-8", "UTF-8",sub='')
        ltoken <- tokenize_words(fileName, lowercase = TRUE, stopwords = NULL, simplify = FALSE)
        ltoken <- unlist(ltoken)
        stemltoken <- wordStem(ltoken) #this uses the Snowball library to lemmatize the entire text.
        textID <- i
        for (p in 1:length(PopScistemsearchedtermlist)) {
          PopScistemsearchedterm <- PopScistemsearchedtermlist[p]
          for (j in 1:length(stemltoken)) {
              if (PopScistemsearchedterm == stemltoken[j]) {
                if (j <= PopScilongconlength) {longtempvec <- ltoken[(1:(j+PopScilongconlength))]}
                if (j > PopScilongconlength) {longtempvec <- ltoken[(j-PopScilongconlength):(j+PopScilongconlength)]}
                if (j <= PopScishortconlength) {shorttempvec <- ltoken[(1:(j+PopScishortconlength))]}
                if (j > PopScishortconlength) {shorttempvec <- ltoken[(j-PopScishortconlength):(j+PopScishortconlength)]}
                if (j <= PopSciPOSconlength) {POStempvec <- ltoken[(1:(j+PopSciPOSconlength))]}
                if (j > PopSciPOSconlength) {POStempvec <- ltoken[(j-PopSciPOSconlength):(j+PopSciPOSconlength)]}
                TempTextName <- gsub(paste0(PopScidoclocation,"/"),"",files[i]) #This grabs just the end of the file path.
                TempTextName <- gsub(".txt","",TempTextName) #This removes the .txt from the end of the name.
                temprow <- matrix(,ncol=12,nrow=1)
                colnames(temprow) <- c("Text", "Text_ID", "PopScistemsearchedterm","Lemma","Lemma_Perc","KWIC","Total_Lemma","Date","Category","Short_KWIC","POS_KWIC","Current_Date")
                temprow[1,1] <- TempTextName
                temprow[1,2] <- textID
                temprow[1,3] <- PopScistemsearchedterm
                temprow[1,4] <- j
                temprow[1,5] <- (j/length(stemltoken))*100
                temprow[1,6] <- as.character(paste(longtempvec,sep= " ",collapse=" "))
                temprow[1,7] <- length(stemltoken)
                temprow[1,8] <- strsplit(TempTextName,"_")[[1]][2]
                #Determining Category
                  if(PopScistemsearchedterm %in% wordStem(PopSciplaysearchedtermlist)) {temprow[1,9] <- "Play-Rhetoric"}
                  if(PopScistemsearchedterm %in% wordStem(PopSciworksearchedtermlist)) {temprow[1,9] <- "Work-Rhetoric"}
                temprow[1,10] <- as.character(paste(shorttempvec,sep= " ",collapse=" "))
                temprow[1,11] <- as.character(paste(POStempvec,sep= " ",collapse=" "))
                temprow[1,12] <- format(Sys.time(), "%Y-%m-%d")
                PopSciWordFlagmat <- rbind(PopSciWordFlagmat,temprow)
              }
          }
        }
        print(files[i]) #let's user watch as code runs for long searches
      }
      PopSciWordFlagmat <- PopSciWordFlagmat[-1,]
      PopSciWordFlagdf <- as.data.frame(PopSciWordFlagmat)
      write.table(PopSciWordFlagdf, PopSciWordFlagdfPath)
      PopSciWordFlagdf[1:5,]
  }else{
    print("Loading the previous dataset as PopSciWordFlagdf")
    PopSciWordFlagdf <- read.table(PopSciWordFlagdfPath)
  }
PopSciWordFlagdf
```

We can then add up the values in SciLifeWordFlagdf to make a table of the frequency of play and work rhetoric, PopSciFreqmat.Again, it's important to do it this way because it lets us assign a random KWIC for later.

```{r,  eval=FALSE}
  # Adding values from PopSciWordFlagdf together to get a matrix of normalized frequencies for each category, as PopSciFreqmat
      PopSciWordFlagPlaydf <- PopSciWordFlagdf[grep("Play-Rhetoric",PopSciWordFlagdf$Category),]
      PopSciWordFlagWorkdf <- PopSciWordFlagdf[grep("Work-Rhetoric",PopSciWordFlagdf$Category),]
      PopSciFreqmat <- matrix(,ncol=9,nrow=1)
      files <- list.files(path = PopScidoclocation, pattern = "txt", full.names = TRUE) #creates vector of txt file names.
      for (i in 1:length(files)) {
        TempTextName <- gsub(paste0(PopScidoclocation,"/"),"",files[i]) #This grabs just the end of the file path.
        TempTextName <- gsub(".txt","",TempTextName) #This removes the .txt from the end of the name.
        tempplaydf <- PopSciWordFlagPlaydf[grep(TempTextName,PopSciWordFlagPlaydf$Text),]
        tempworkdf <- PopSciWordFlagWorkdf[grep(TempTextName,PopSciWordFlagWorkdf$Text),]
        TempDate <- strsplit(TempTextName,"_")[[1]][2]
        #to be honest, TempLength got a way from me a bit, since not all tempplaydf and
              #tempworkdf will have values.  So I kind of jury rigged an answer.
              if(nrow(tempplaydf) >0) {TempLength <- tempplaydf$Total_Lemma[1]}else{TempLength <- tempworkdf$Total_Lemma[1]}
        temprows <- matrix(,ncol=9,nrow=2)
        colnames(temprows) <- c("Text", "Text_ID","Date","Category","Frequency","Total_Lemma","Normalized_Freq","Sample_KWIC","Avg_Lemma_Perc")
        temprows[1:2,1] <- as.character(TempTextName)
        temprows[1:2,2] <- i
        temprows[1:2,3] <- as.character(TempDate)
        temprows[1,4] <- "Play-Rhetoric"
        temprows[2,4] <- "Work-Rhetoric"
        temprows[1,5] <- nrow(tempplaydf)
        temprows[2,5] <- nrow(tempworkdf)
        temprows[1:2,6]<- as.character(TempLength)
        temprows[1,7] <- (as.numeric(temprows[1,5])/as.numeric(temprows[1,6]))*100
        temprows[2,7] <- (as.numeric(temprows[2,5])/as.numeric(temprows[2,6]))*100
        #temprows[1,8]
          if(nrow(tempplaydf) > 0){temprows[1,8] <- as.character(sample(tempplaydf$Short_KWIC,1))}else{temprows[1,8] <- NA}
        #temprows[2,8]
          if(nrow(tempworkdf) >0) {temprows[2,8] <- as.character(sample(tempworkdf$Short_KWIC,1))}else{temprows[2,8] <- NA}
        temprows[1,9] <- mean(as.numeric(as.character(tempplaydf$Lemma_Perc)))
        temprows[2,9] <- mean(as.numeric(as.character(tempworkdf$Lemma_Perc)))
        PopSciFreqmat <- rbind(PopSciFreqmat,temprows)
      }
      PopSciFreqmat <- PopSciFreqmat[-1,]
      PopSciFreqdf <- as.data.frame(PopSciFreqmat)
      PopSciFreqdf
```

With the data in hand, we can now ask some questions about our popular science corpus, such as: Do references to play or work rhetoric in Victorian popular science increase over the course of the century (play doesn't, although work might rise a bit). (This time I've skipped the test of making a non-interactable plot.)

```{r,  eval=FALSE}
# Visualizing PopSciFreqdf BY DATE
      p <- ggplot(PopSciFreqdf, aes(y = as.numeric(as.character(Normalized_Freq)), x = as.numeric(as.character(Date)), color = Category, label = Sample_KWIC))
      pg <- geom_point(size=1,pch = 16)
      pl <- p + pg + labs(x = "Date", y = "Normalized Frequency (% of Words in Text)", title = "Appearances of Play and Work Rhetoric within 19th-Century Popular Science")
      ggplotly(pl)
```

Do Victorian Popular Science texts increase in length over the course of the century? (Answer: they don't)

```{r,  eval=FALSE}
# Visualizing Average Lemma Locations
      p <- ggplot(PopSciFreqdf, aes(y = as.numeric(as.character(Total_Lemma)), x = as.numeric(as.character(Date))))
      pg <- geom_point(size=1,pch = 16)
      pl <- p + pg + labs(x = "Date", y = "Length of Document (by Words)", title = "Length of Victorian Popular Science")
      pl
```

Does the average place when play or work rhetoric are utlized vary with date? (Answer: Well that's interesting. I have less texts from the early 19th, so I can't be certain, but it APPEARS that (contrary to what one might expect), play and work become increasingly mixed up in popular science texts.)

```{r,  eval=FALSE}
      p <- ggplot(PopSciFreqdf, aes(y = as.numeric(as.character(Avg_Lemma_Perc)), x = as.numeric(as.character(Date)), color = Category, label = Sample_KWIC))
      pg <- geom_point(size=1,pch = 16)
      pl <- p + pg + labs(x = "Date", y = "Average Position in Text (by Percentage)", title = "Appearances of Play and Work Rhetoric within \nVictorian Popular Science")
      ggplotly(pl)
```

We can also visualize the terms which most frequently occur around the search terms in the two categories within this corpus.
```{r Victorian Popular Science Work/Play Associations,  eval=FALSE}
  PopSciWordFlagdf$Text <- as.character(PopSciWordFlagdf$Text)
  PopSciWordFlagdf$KWIC <- as.character(PopSciWordFlagdf$KWIC)
corpus <- corpus(PopSciWordFlagdf, 
                 docid_field="Text", 
                 text_field="KWIC")
group_PopSciWordFlagdfm <- dfm(corpus, remove=c(stopwords("en"),PopScisearchedtermlist), remove_punct=TRUE, remove_numbers = TRUE, groups="Category")
textplot_wordcloud(group_PopSciWordFlagdfm,max.words=50, colors = RColorBrewer::brewer.pal(8,"Dark2"), comparison=TRUE)


```

Finally, we can run a very rudimentary qualitative sentiment analysis by looking at JUST the adjectives which appear around the term (for instance, within a 10 word range on either side). This requires part of speech (POS) tagging, which can take a very long time, which is why we are working from the "POS_KWIC" column of "PopSciWordFlagdf." This also requires the use of the coreNLP library, which can take a long time to install and initialize, So this section has an extra parameter to initialize it.  

**IMPORTANT NOTE: Since creating a Word Flag matrix can take a nontrivial amount of time for larger corpuses, this script is designed only to run the program to create a new PopSciWordFlagdf if there is a change to the dataset in folder "Documents" or if the previous PopSciKWICPOSplaydf and PopSciKWICPOSworkdf has been deleted. Otherwise it simply calls up the last dataset.**

First we set the parameters for naming the datasets we make.
```{r DECPopSciPOSApp parameter,  eval=FALSE}
    PopSciKWICPOSplaydfPath <- paste0(PopScioutputlocation,"/","PopSciKWICPOSplaydf.txt")
    PopSciKWICPOSworkdfPath <- paste0(PopScioutputlocation,"/","PopSciKWICPOSworkdf.txt")
```

Then we run a script which either creates new POS data or calls up the last set.

```{R DECPopSciPOSApp,  eval=FALSE}
   if(file.exists(PopSciKWICPOSplaydfPath)&file.exists(PopSciKWICPOSworkdfPath) == TRUE) {
        PopSciDataChange3 <- FALSE
        print("The previous PopSciWordFlagdf still exists.")
      }else{
        PopSciDataChange3 <- TRUE
        print("The previous PopSciKWICPOSplaydf or PopSciKWICPOSworkdf seems to have been moved or deleted.  A new PopSciKWICPOSdf will therefore be created.")
        }
  
  if(PopSciDataChange1|PopSciDataChange3 == TRUE) {
    #we run part of speech tagging on each of these KWIC and draw out just the adjectives, and sum up the numbers.
      #We do this for the play rhetoric data.
        ADJADVplaydf <- data.frame( Var1=character(),Freq=numeric())
        for(i in 1:nrow(PopSciWordFlagPlaydf)) {
          tempstring <- as.character(PopSciWordFlagPlaydf$POS_KWIC[i])
          anno <- annotateString(tempstring)
          token <- getToken(anno)
          ut <- universalTagset(token$POS)
          index <- c(which(ut=="ADJ"), which(ut=="ADV"))
          temptable <- table(token$lemma[index])
          ADJADVplaydf <- rbind(ADJADVplaydf,as.data.frame(temptable))
          print(paste0(i, " out of ",nrow(PopSciWordFlagPlaydf)))
        }
        ADJADVplaydf <- aggregate(ADJADVplaydf$Freq, b=list(Category=ADJADVplaydf$Var1), FUN=sum)
        PopSciKWICPOSplaydf <- ADJADVplaydf[order(ADJADVplaydf$x, decreasing=TRUE),]  #reordering the matrix
        write.table(PopSciKWICPOSplaydf, PopSciKWICPOSplaydfPath)
        
      #And for the work rhetoric data.
        ADJADVworkdf <- data.frame( Var1=character(),Freq=numeric())
        for(i in 1:nrow(PopSciWordFlagWorkdf)) {
          tempstring <- as.character(PopSciWordFlagWorkdf$POS_KWIC[i])
          anno <- annotateString(tempstring)
          token <- getToken(anno)
          ut <- universalTagset(token$POS)
          index <- c(which(ut=="ADJ"), which(ut=="ADV"))
          temptable <- table(token$lemma[index])
          ADJADVworkdf <- rbind(ADJADVworkdf,as.data.frame(temptable))
          print(paste0(i, " out of ",nrow(PopSciWordFlagWorkdf)))
        }
        ADJADVworkdf <- aggregate(ADJADVworkdf$Freq, b=list(Category=ADJADVworkdf$Var1), FUN=sum)
        PopSciKWICPOSworkdf <- ADJADVworkdf[order(ADJADVworkdf$x, decreasing=TRUE),]  #reordering the matrix
        write.table(PopSciKWICPOSworkdf, PopSciKWICPOSworkdfPath)
  }else{
    print("Loading the previous datasets as PopSciKWICPOSplaydf and PopSciKWICPOSworkdf")
    PopSciKWICPOSplaydf <- read.table(PopSciKWICPOSplaydfPath)
    PopSciKWICPOSworkdf <- read.table(PopSciKWICPOSworkdfPath)
  }
PopSciKWICPOSplaydf
PopSciKWICPOSworkdf
```

And finally we visualize the top 25 adjectives and adverbs. This has some clear errors: it's doubtful that the Victorians were a big fan of the word "digitized". 

```{R DECPopSciPOSApp Visual,  eval=FALSE}
        TopADJADVplaydf <- PopSciKWICPOSplaydf[1:25,]
        TopADJADVplaydf$Category <- factor(TopADJADVplaydf$Category, levels = TopADJADVplaydf$Category[order(TopADJADVplaydf$x)])
        TopADJADVworkdf <- PopSciKWICPOSworkdf[1:25,]
        TopADJADVworkdf$Category <- factor(TopADJADVworkdf$Category, levels = TopADJADVworkdf$Category[order(TopADJADVworkdf$x)])
    
        #Then we visualize the top 25 adjectives and adverbs for work and play rhetoric.
           p1 <- ggplot(TopADJADVplaydf, aes(y = as.numeric(as.character(x)), x = (Category)))
           p2 <- geom_bar(stat="identity") 
           p3 <- p1 + p2 + labs(x = "Adjective/Adverb near Play Rhetoric", y = "Frequency", title = "Common Adjectives and Adverbs near Play Rhetoric \nwithin Victorian Popular Science")
           pl1 <- p3+coord_flip()
          
            p4 <- ggplot(TopADJADVworkdf, aes(y = as.numeric(as.character(x)), x = (Category)))
           p5 <- geom_bar(stat="identity") 
           p6 <- p4 + p5 + labs(x = "Adjective/Adverb near Play Rhetoric", y = "Frequency", title = "Common Adjectives and Adverbs near Work Rhetoric \nwithin Victorian Popular Science")
           pl2 <- p6+coord_flip()
           {print(pl1)
           print(pl2)}
```